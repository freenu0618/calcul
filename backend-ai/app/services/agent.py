"""
LangGraph Agent ì„œë¹„ìŠ¤
ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ + RAG (ë²•ë ¹ ê²€ìƒ‰) + Tool Calling + ëŒ€í™” ížˆìŠ¤í† ë¦¬
"""

import logging
import json
import httpx
from typing import AsyncGenerator, Optional
from collections import defaultdict
from dataclasses import dataclass, field

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage

from app.services.llm import get_tiered_llm
from app.services.prompts import SYSTEM_PROMPT
from app.services.rag import get_rag_service
from app.services.tools import ALL_TOOLS, GENERAL_TOOLS, USER_DATA_TOOLS, set_user_token
from app.core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


# ==================== ì„¸ì…˜ ê´€ë¦¬ ====================

@dataclass
class UserSession:
    """ì‚¬ìš©ìž ì„¸ì…˜ ì •ë³´"""
    user_name: str = ""
    user_email: str = ""
    messages: list = field(default_factory=list)  # [(role, content), ...]

# ì„¸ì…˜ ì €ìž¥ì†Œ (ë©”ëª¨ë¦¬ ê¸°ë°˜, ì¶”í›„ Redis/DBë¡œ ì „í™˜ ê°€ëŠ¥)
_sessions: dict[str, UserSession] = defaultdict(UserSession)
MAX_HISTORY = 10  # ìµœëŒ€ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ìˆ˜


async def _fetch_user_info(token: str) -> tuple[str, str]:
    """ì‚¬ìš©ìž ê¸°ë³¸ ì •ë³´ (ì´ë¦„, ì´ë©”ì¼) ì¡°íšŒ"""
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            resp = await client.get(
                f"{settings.spring_api_url}/api/v1/auth/me",
                headers={"Authorization": f"Bearer {token}"},
            )
            if resp.status_code == 200:
                data = resp.json().get("data", {})
                return data.get("name", ""), data.get("email", "")
    except Exception as e:
        logger.warning(f"User info fetch failed: {e}")
    return "", ""


async def _execute_tool(tool_name: str, tool_args: dict) -> str:
    """Tool ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
    tool_map = {t.name: t for t in ALL_TOOLS}

    if tool_name not in tool_map:
        return json.dumps({"error": f"Unknown tool: {tool_name}"})

    try:
        tool = tool_map[tool_name]
        result = await tool.ainvoke(tool_args)
        return json.dumps(result, ensure_ascii=False, default=str)
    except Exception as e:
        logger.error(f"Tool execution error ({tool_name}): {e}")
        return json.dumps({"error": str(e)})


async def _invoke_with_fallback(tiered_llm, messages: list, tools: list):
    """LLM í˜¸ì¶œ with fallback (Tool Calling ì§€ì›)"""
    logger.info(f"_invoke_with_fallback called, tiers: {[n for n,_ in tiered_llm.tiers]}")
    last_error = None

    for name, llm in tiered_llm.tiers:
        cb = tiered_llm.circuit_breakers[name]
        if not cb.can_execute():
            logger.debug(f"Skipping {name} (circuit open)")
            continue

        try:
            llm_with_tools = llm.bind_tools(tools)
            response = await llm_with_tools.ainvoke(messages)
            cb.record_success()
            logger.info(f"LLM response from {name}")
            return response
        except Exception as e:
            cb.record_failure()
            last_error = e
            logger.warning(f"{name} failed: {e}")
            continue

    raise RuntimeError(f"All LLM tiers failed: {last_error}")


async def get_agent_response(
    message: str,
    session_id: Optional[str] = None,
    user_token: Optional[str] = None,
) -> AsyncGenerator[dict, None]:
    """
    ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° (Tool Calling + ëŒ€í™” ížˆìŠ¤í† ë¦¬)

    Args:
        message: ì‚¬ìš©ìž ë©”ì‹œì§€
        session_id: ì„¸ì…˜ ID (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ìš©)
        user_token: JWT í† í° (ì‚¬ìš©ìž ë°ì´í„° ì¡°íšŒìš©)

    Yields:
        {"type": "token"|"citation"|"tool_call"|"done"|"error", "data": ...}
    """
    try:
        tiered_llm = get_tiered_llm()
        rag_service = get_rag_service()

        # ì‚¬ìš©ìž í† í° ì„¤ì • (Toolì—ì„œ ì‚¬ìš©)
        set_user_token(user_token)

        # ì„¸ì…˜ ê´€ë¦¬ (session_idê°€ ì—†ìœ¼ë©´ ìƒˆ ì„¸ì…˜)
        session_key = session_id or "default"
        session = _sessions[session_key]

        # ì‚¬ìš©ìž ì •ë³´ ì¡°íšŒ (ì„¸ì…˜ì— ì—†ìœ¼ë©´ API í˜¸ì¶œ)
        user_name = session.user_name
        if user_token and not user_name:
            user_name, user_email = await _fetch_user_info(user_token)
            session.user_name = user_name
            session.user_email = user_email
            logger.info(f"User info loaded: {user_name}")

        # RAG: ê´€ë ¨ ë²•ë ¹ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
        rag_context = await rag_service.get_context(message)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_content = SYSTEM_PROMPT

        # ì‚¬ìš©ìž ì´ë¦„ ì¶”ê°€
        if user_name:
            system_content += f"\n\ní˜„ìž¬ ì‚¬ìš©ìž: {user_name}ë‹˜"

        # Tool ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì•ˆë‚´
        if user_token:
            system_content += """

[ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬]
ë¡œê·¸ì¸ëœ ì‚¬ìš©ìžì´ë¯€ë¡œ ë‹¤ìŒ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:
- get_my_employees: ì§ì› ëª©ë¡ ì¡°íšŒ ("ì§ì› ëˆ„êµ¬ì•¼", "ì§ì› ëª…ë‹¨" ë“±)
- get_employee_detail: íŠ¹ì • ì§ì› ìƒì„¸ ì¡°íšŒ ("ê¹€ì² ìˆ˜ ì •ë³´", "í™ê¸¸ë™ ê¸‰ì—¬" ë“±)
- get_payroll_summary: ê¸‰ì—¬ëŒ€ìž¥ ìš”ì•½ ("ì´ë²ˆë‹¬ ì¸ê±´ë¹„", "ê¸‰ì—¬ ì´ì•¡" ë“±)
- get_monthly_labor_cost: íŠ¹ì • ì›” ì¸ê±´ë¹„ ì¡°íšŒ
- salary_calculator: ê¸‰ì—¬ ê³„ì‚° ì‹œë®¬ë ˆì´ì…˜
- insurance_calculator: 4ëŒ€ë³´í—˜ ê³„ì‚°

ì‚¬ìš©ìžê°€ ì§ì›ì´ë‚˜ ê¸‰ì—¬ ë°ì´í„°ë¥¼ ë¬¼ì–´ë³´ë©´ ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""
        else:
            system_content += """

[ì¤‘ìš” ì•ˆë‚´]
í˜„ìž¬ ë¡œê·¸ì¸ë˜ì–´ ìžˆì§€ ì•ŠìŠµë‹ˆë‹¤.
ì§ì› ëª©ë¡ ì¡°íšŒ, ê¸‰ì—¬ëŒ€ìž¥ í™•ì¸, ê°œì¸í™”ëœ ê¸‰ì—¬ ê³„ì‚° ë“±ì˜ ê¸°ëŠ¥ì„ ì´ìš©í•˜ì‹œë ¤ë©´ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
ì¼ë°˜ì ì¸ ë…¸ë™ë²• ìƒë‹´, ê¸‰ì—¬ ê³„ì‚° ì‹œë®¬ë ˆì´ì…˜, 4ëŒ€ ë³´í—˜ ê³„ì‚°ì€ ë¡œê·¸ì¸ ì—†ì´ë„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìžì—ê²ŒëŠ” ë©´ì±… ì¡°í•­ ëŒ€ì‹  ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
"ðŸ’¡ ë¡œê·¸ì¸í•˜ì‹œë©´ ì§ì› ê´€ë¦¬, ê¸‰ì—¬ëŒ€ìž¥ ì¡°íšŒ ë“± ë” ë§Žì€ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
"""

        # ë²•ë ¹ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if rag_context.context_text:
            system_content += f"\n\n{rag_context.context_text}"
            logger.info(f"RAG: {len(rag_context.relevant_articles)} articles added")

        # ë©”ì‹œì§€ êµ¬ì„± (ì‹œìŠ¤í…œ + ì´ì „ ëŒ€í™” + í˜„ìž¬ ë©”ì‹œì§€)
        messages = [SystemMessage(content=system_content)]

        # ì´ì „ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœëŒ€ MAX_HISTORYê°œ)
        for role, content in session.messages[-MAX_HISTORY:]:
            if role == "user":
                messages.append(HumanMessage(content=content))
            else:
                messages.append(AIMessage(content=content))

        # í˜„ìž¬ ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
        messages.append(HumanMessage(content=message))

        # Tool ë°”ì¸ë”© (ë¡œê·¸ì¸ëœ ê²½ìš° ì „ì²´, ì•„ë‹ˆë©´ ì¼ë°˜ ë„êµ¬ë§Œ)
        tools = ALL_TOOLS if user_token else GENERAL_TOOLS

        # Tool Calling ë£¨í”„ (ìµœëŒ€ 3íšŒ)
        max_iterations = 3
        full_response = ""

        for iteration in range(max_iterations):
            # LLM í˜¸ì¶œ (fallback ì§€ì›)
            response = await _invoke_with_fallback(tiered_llm, messages, tools)

            # Tool Callì´ ìžˆëŠ”ì§€ í™•ì¸
            if hasattr(response, "tool_calls") and response.tool_calls:
                messages.append(response)  # AI ë©”ì‹œì§€ ì¶”ê°€

                for tool_call in response.tool_calls:
                    tool_name = tool_call.get("name", "")
                    tool_args = tool_call.get("args", {})
                    tool_id = tool_call.get("id", "")

                    logger.info(f"Tool call: {tool_name}({tool_args})")

                    # Tool í˜¸ì¶œ ì•Œë¦¼
                    yield {
                        "type": "tool_call",
                        "data": {"tool": tool_name, "status": "start"}
                    }

                    # Tool ì‹¤í–‰
                    result = await _execute_tool(tool_name, tool_args)

                    # Tool ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€
                    messages.append(ToolMessage(content=result, tool_call_id=tool_id))

                    yield {
                        "type": "tool_call",
                        "data": {"tool": tool_name, "status": "end", "result": result[:200]}
                    }

                continue  # ë‹¤ì‹œ LLM í˜¸ì¶œ

            # Tool Callì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µ
            if hasattr(response, "content") and response.content:
                full_response = response.content
                break

        # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ (í† í° ë‹¨ìœ„ê°€ ì•„ë‹Œ ë¬¸ìž¥ ë‹¨ìœ„)
        if full_response:
            # ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
            sentences = full_response.replace(".", ".|").replace("!", "!|").replace("?", "?|").split("|")
            for sentence in sentences:
                if sentence.strip():
                    yield {"type": "token", "data": sentence}

        # ëŒ€í™” ížˆìŠ¤í† ë¦¬ì— ì €ìž¥
        session.messages.append(("user", message))
        session.messages.append(("assistant", full_response))

        # ížˆìŠ¤í† ë¦¬ ìµœëŒ€ í¬ê¸° ì œí•œ
        if len(session.messages) > MAX_HISTORY * 2:
            session.messages = session.messages[-MAX_HISTORY * 2:]

        yield {"type": "done", "data": ""}

    except Exception as e:
        logger.error(f"Agent error: {e}")
        # ì‚¬ìš©ìž ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
        user_message = "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        yield {"type": "error", "data": user_message}


async def get_agent_response_streaming(
    message: str,
    session_id: Optional[str] = None,
    user_token: Optional[str] = None,
) -> AsyncGenerator[dict, None]:
    """
    ìŠ¤íŠ¸ë¦¬ë° ì „ìš© ì‘ë‹µ (Tool Calling ì—†ì´ ë¹ ë¥¸ ì‘ë‹µ)
    ë‹¨ìˆœ ì§ˆë¬¸ì´ë‚˜ ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•  ë•Œ ì‚¬ìš©
    """
    try:
        tiered_llm = get_tiered_llm()
        rag_service = get_rag_service()

        # ì„¸ì…˜ ê´€ë¦¬
        session_key = session_id or "default"
        session = _sessions[session_key]

        # RAG ì»¨í…ìŠ¤íŠ¸
        rag_context = await rag_service.get_context(message)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = SYSTEM_PROMPT
        if rag_context.context_text:
            system_content += f"\n\n{rag_context.context_text}"

        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [SystemMessage(content=system_content)]
        for role, content in session.messages[-MAX_HISTORY:]:
            if role == "user":
                messages.append(HumanMessage(content=content))
            else:
                messages.append(AIMessage(content=content))
        messages.append(HumanMessage(content=message))

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        buffer = ""
        full_response = ""
        flush_chars = {" ", ".", ",", "!", "?", "\n", ":", ";", ")", "]", "}", "â€»"}

        async for chunk in tiered_llm.astream(messages):
            if hasattr(chunk, "content") and chunk.content:
                buffer += chunk.content
                full_response += chunk.content

                if buffer and buffer[-1] in flush_chars:
                    yield {"type": "token", "data": buffer}
                    buffer = ""

        if buffer:
            yield {"type": "token", "data": buffer}

        # ížˆìŠ¤í† ë¦¬ ì €ìž¥
        session.messages.append(("user", message))
        session.messages.append(("assistant", full_response))

        if len(session.messages) > MAX_HISTORY * 2:
            session.messages = session.messages[-MAX_HISTORY * 2:]

        yield {"type": "done", "data": ""}

    except Exception as e:
        logger.error(f"Streaming agent error: {e}")
        yield {"type": "error", "data": str(e)}
